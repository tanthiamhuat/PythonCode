{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/42480787/loading-selected-file-from-sftp-to-s3-using-python\n",
    "# connect to SFTP Server\n",
    "# hostname : sftp.sitr.suezsmartsolutions.com      \n",
    "# Username : SINGAPORE\n",
    "# Password : S1n9ap0r3PF337£\n",
    "# Port Number: 8122\n",
    "host = 'sftp.sitr.suezsmartsolutions.com'\n",
    "username = 'SINGAPORE'\n",
    "password = 'S1n9ap0r3PF337£'\n",
    "port = 8122\n",
    "sftp_dir = '/SINGAPORE/Data/Output/consumption_processed'\n",
    "     \n",
    "chunk_size = 12428800\n",
    "s3_id = 'AKIAI4IECUWYFJSO56ZQ'\n",
    "s3_key = 'kCjI7f0Ccr9BoN5joo8JoYafD3MXOVe/1zMwxrKc'\n",
    "bucket_name = 'consumption2019'\n",
    "\n",
    "import math\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import datetime\n",
    "import paramiko\n",
    "import SSHLibrary\n",
    "from stat import S_ISDIR\n",
    "from boto.s3.connection import S3Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftpTransport = paramiko.Transport((host, port))\n",
    "sftpTransport.connect(username = username, password = password)\n",
    "sftp_conn = paramiko.SFTPClient.from_transport(sftpTransport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_conn = S3Connection(s3_id, s3_key)\n",
    "bucket = s3_conn.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_file(filepath):\n",
    "    key_id = filepath.replace(sftp_dir, '').lstrip('/')\n",
    "    key = bucket.get_key(key_id)\n",
    "    sftp_fi = sftp_conn.file(filepath, 'r')\n",
    "    source_size = sftp_fi._get_size()\n",
    "    if key is not None:\n",
    "        # check if we need to replace, check sizes\n",
    "        if source_size == key.size:\n",
    "            print('%s already uploaded' % key_id)\n",
    "            sftp_fi.close()\n",
    "            return\n",
    "\n",
    "    chunk_count = int(math.ceil(source_size / float(chunk_size)))\n",
    "    mp = bucket.initiate_multipart_upload(key_id)\n",
    "\n",
    "    print('%s uploading size: %imb, %i chunks' % (\n",
    "        key_id, math.ceil(source_size/1024/1024), chunk_count))\n",
    "    for i in range(chunk_count):\n",
    "        start = time.time()\n",
    "        chunk = sftp_fi.read(chunk_size)\n",
    "        end = time.time()\n",
    "        seconds = end - start\n",
    "        print('%s read chunk from sftp (%i/%i) %ikbs' % (\n",
    "            key_id, i + 1, chunk_count,\n",
    "            math.ceil((chunk_size / 1024) / seconds)))\n",
    "\n",
    "        fp = io.BytesIO(chunk)\n",
    "        start = time.time()\n",
    "        mp.upload_part_from_file(fp, part_num=i + 1)\n",
    "        end = time.time()\n",
    "        seconds = end - start\n",
    "        print('%s upload chunk to s3 (%i/%i) %ikbs' % (\n",
    "            key_id, i + 1, chunk_count,\n",
    "            math.ceil((chunk_size / 1024) / seconds)))\n",
    "\n",
    "    mp.complete_upload()\n",
    "    sftp_fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_dir(directory):\n",
    "    sftp_conn.chdir(directory)\n",
    "    for filename in sftp_conn.listdir():\n",
    "        if (filename[:5] =='CC_19'):    \n",
    "            filepath = os.path.join(directory, filename)\n",
    "            if S_ISDIR(sftp_conn.stat(filepath).st_mode):\n",
    "                move_dir(filepath)\n",
    "            else:\n",
    "                move_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_190101204001.csv already uploaded\n",
      "CC_190104124000.csv already uploaded\n",
      "CC_190103164000.csv already uploaded\n",
      "CC_190101074001.csv already uploaded\n",
      "CC_190102144000.csv already uploaded\n",
      "CC_190101134000.csv already uploaded\n",
      "CC_190102224000.csv already uploaded\n",
      "CC_190106054000.csv already uploaded\n",
      "CC_190104034000.csv already uploaded\n",
      "CC_190103204000.csv already uploaded\n",
      "CC_190104024000.csv already uploaded\n",
      "CC_190103224000.csv already uploaded\n",
      "CC_190101044003.csv already uploaded\n",
      "CC_190104014000.csv already uploaded\n",
      "CC_190107074011.csv already uploaded\n",
      "CC_190103114000.csv already uploaded\n",
      "CC_190103134000.csv already uploaded\n",
      "CC_190102014000.csv already uploaded\n",
      "CC_190107094011.csv uploading size: 1mb, 1 chunks\n",
      "CC_190107094011.csv read chunk from sftp (1/1) 7418kbs\n",
      "CC_190107094011.csv upload chunk to s3 (1/1) 436765kbs\n",
      "CC_190105044004.csv already uploaded\n",
      "CC_190105024000.csv already uploaded\n",
      "CC_190102134000.csv already uploaded\n",
      "CC_190106184000.csv already uploaded\n",
      "CC_190106114000.csv already uploaded\n",
      "CC_190104044001.csv already uploaded\n",
      "CC_190103144001.csv already uploaded\n",
      "CC_190103004000.csv already uploaded\n",
      "CC_190102204000.csv already uploaded\n",
      "CC_190104064000.csv already uploaded\n",
      "CC_190105234000.csv already uploaded\n",
      "CC_190105054000.csv already uploaded\n",
      "CC_190106014000.csv already uploaded\n",
      "CC_190102084001.csv already uploaded\n",
      "CC_190101104000.csv already uploaded\n",
      "CC_190104004000.csv already uploaded\n",
      "CC_190103034001.csv already uploaded\n",
      "CC_190106074000.csv already uploaded\n",
      "CC_190101024000.csv already uploaded\n",
      "CC_190101174000.csv already uploaded\n",
      "CC_190101054000.csv already uploaded\n",
      "CC_190102044001.csv already uploaded\n",
      "CC_190105154000.csv already uploaded\n",
      "CC_190104194001.csv already uploaded\n",
      "CC_190101164002.csv already uploaded\n",
      "CC_190106174000.csv already uploaded\n",
      "CC_190107044005.csv already uploaded\n",
      "CC_190103083959.csv already uploaded\n",
      "CC_190106024000.csv already uploaded\n",
      "CC_190101214000.csv already uploaded\n",
      "CC_190103124000.csv already uploaded\n",
      "CC_190106224001.csv already uploaded\n",
      "CC_190102094000.csv already uploaded\n",
      "CC_190104074000.csv already uploaded\n",
      "CC_190102104000.csv already uploaded\n",
      "CC_190104174000.csv already uploaded\n",
      "CC_190103064000.csv already uploaded\n",
      "CC_190105084000.csv already uploaded\n",
      "CC_190102174000.csv already uploaded\n",
      "CC_190104084000.csv already uploaded\n",
      "CC_190107054011.csv already uploaded\n",
      "CC_190103234002.csv already uploaded\n",
      "CC_190105064000.csv already uploaded\n",
      "CC_190106144000.csv already uploaded\n",
      "CC_190106064001.csv already uploaded\n",
      "CC_190102164000.csv already uploaded\n",
      "CC_190102214000.csv already uploaded\n",
      "CC_190101064000.csv already uploaded\n",
      "CC_190104204000.csv already uploaded\n",
      "CC_190104054001.csv already uploaded\n",
      "CC_190101014000.csv already uploaded\n",
      "CC_190107024010.csv already uploaded\n",
      "CC_190104104000.csv already uploaded\n",
      "CC_190106154000.csv already uploaded\n",
      "CC_190101124000.csv already uploaded\n",
      "CC_190105094000.csv already uploaded\n",
      "CC_190106234000.csv already uploaded\n",
      "CC_190105134000.csv already uploaded\n",
      "CC_190104094000.csv already uploaded\n",
      "CC_190101034003.csv already uploaded\n",
      "CC_190105074000.csv already uploaded\n",
      "CC_190104184001.csv already uploaded\n",
      "CC_190103014000.csv already uploaded\n",
      "CC_190102124000.csv already uploaded\n",
      "CC_190103074000.csv already uploaded\n",
      "CC_190101224000.csv already uploaded\n",
      "CC_190106204001.csv already uploaded\n",
      "CC_190102054000.csv already uploaded\n",
      "CC_190105124000.csv already uploaded\n",
      "CC_190103024000.csv already uploaded\n",
      "CC_190104224000.csv already uploaded\n",
      "CC_190104134000.csv already uploaded\n",
      "CC_190106214000.csv already uploaded\n",
      "CC_190103214000.csv already uploaded\n",
      "CC_190102034001.csv already uploaded\n",
      "CC_190102074000.csv already uploaded\n",
      "CC_190103194001.csv already uploaded\n",
      "CC_190107064006.csv already uploaded\n",
      "CC_190107034012.csv already uploaded\n",
      "CC_190104164000.csv already uploaded\n",
      "CC_190102184000.csv already uploaded\n",
      "CC_190105004000.csv already uploaded\n",
      "CC_190105224001.csv already uploaded\n",
      "CC_190101194000.csv already uploaded\n",
      "CC_190107084002.csv uploading size: 1mb, 1 chunks\n",
      "CC_190107084002.csv read chunk from sftp (1/1) 9149kbs\n",
      "CC_190107084002.csv upload chunk to s3 (1/1) 192180kbs\n",
      "CC_190103174000.csv already uploaded\n",
      "CC_190106164001.csv already uploaded\n",
      "CC_190101144009.csv already uploaded\n",
      "CC_190105204000.csv already uploaded\n",
      "CC_190106194000.csv already uploaded\n",
      "CC_190101114000.csv already uploaded\n",
      "CC_190104214001.csv already uploaded\n",
      "CC_190104144000.csv already uploaded\n",
      "CC_190106084001.csv already uploaded\n",
      "CC_190101184000.csv already uploaded\n",
      "CC_190106034003.csv already uploaded\n",
      "CC_190106004000.csv already uploaded\n",
      "CC_190101234000.csv already uploaded\n",
      "CC_190105034001.csv already uploaded\n",
      "CC_190103044002.csv already uploaded\n",
      "CC_190105164000.csv already uploaded\n",
      "CC_190106104001.csv already uploaded\n",
      "CC_190102154000.csv already uploaded\n",
      "CC_190101154000.csv already uploaded\n",
      "CC_190102234000.csv already uploaded\n",
      "CC_190105194000.csv already uploaded\n",
      "CC_190105184000.csv already uploaded\n",
      "CC_190105104000.csv already uploaded\n",
      "CC_190105174001.csv already uploaded\n",
      "CC_190106134000.csv already uploaded\n",
      "CC_190105214000.csv already uploaded\n",
      "CC_190107014005.csv already uploaded\n",
      "CC_190101004003.csv already uploaded\n",
      "CC_190105144000.csv already uploaded\n",
      "CC_190102114000.csv already uploaded\n",
      "CC_190101084004.csv already uploaded\n",
      "CC_190104234000.csv already uploaded\n",
      "CC_190106044000.csv already uploaded\n",
      "CC_190102004000.csv already uploaded\n",
      "CC_190105014000.csv already uploaded\n",
      "CC_190105114000.csv already uploaded\n",
      "CC_190107004005.csv already uploaded\n",
      "CC_190106094000.csv already uploaded\n",
      "CC_190102194000.csv already uploaded\n",
      "CC_190102024000.csv already uploaded\n",
      "CC_190106124000.csv already uploaded\n",
      "CC_190103184000.csv already uploaded\n",
      "CC_190103054000.csv already uploaded\n",
      "CC_190104154001.csv already uploaded\n"
     ]
    }
   ],
   "source": [
    "move_dir(sftp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
